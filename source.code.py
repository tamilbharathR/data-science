# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bvAjjWWHk5G-gPNfctvKpD6lXc6oMhHD

#‚úÖ Updated Project Code
"""

# Decoding Emotions through Sentiment Analysis of Social Media Conversation

# Step 1: Upload the Dataset
from google.colab import files
uploaded = files.upload()

"""#Load the Dataset"""

# Step 2: Load the Dataset
import pandas as pd

# Replace with your actual file name if different
df = pd.read_csv('twitter_training.csv', encoding='latin1')

"""#Data Exploration"""

df.head()

print("Shape:", df.shape)
print("Columns:", df.columns.tolist())
df.info()
df.isnull().sum()
df.duplicated().sum()

"""#Check for Missing Values and Duplicates"""

# Check for missing values
missing_values = df.isnull().sum()
print("Missing Values:\n", missing_values)

# Check for duplicate rows
duplicate_rows = df.duplicated().sum()
print("\nNumber of Duplicate Rows:", duplicate_rows)

"""#Visualize a Few Features"""

# üìå Step 1: Import Libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# üìå Step 2: Load Dataset
df = pd.read_csv("twitter_training.csv", header=None)

# Confirm number of columns (should be 4)
df.columns = ['ID', 'user', 'emotion', 'tweet']

# Keep only needed columns
df = df[['emotion', 'tweet']]

# Remove missing or empty rows
df.dropna(inplace=True)
df = df[df['tweet'].str.strip() != '']

plt.figure(figsize=(10, 5))
sns.countplot(data=df, x='emotion', order=df['emotion'].value_counts().index, palette='Set2')
plt.title("Distribution of Emotions in Tweets")
plt.xlabel("Emotion")
plt.ylabel("Number of Tweets")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df['tweet_length'] = df['tweet'].apply(lambda x: len(str(x)))

plt.figure(figsize=(8, 5))
sns.histplot(df['tweet_length'], bins=30, kde=True, color='skyblue')
plt.title("Tweet Length Distribution")
plt.xlabel("Length of Tweet (Characters)")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

"""#Identify Target and Features"""

# Load dataset
import pandas as pd

df = pd.read_csv("twitter_training.csv", header=None)
df.columns = ['ID', 'user', 'emotion', 'tweet']

# Keep only the required columns
df = df[['emotion', 'tweet']]

# Drop missing or empty tweets
df.dropna(inplace=True)
df = df[df['tweet'].str.strip() != '']

# Identify feature and target
X = df['tweet']       # Feature: tweet text
y = df['emotion']     # Target: emotion label

# Display a sample
print("üîπ Sample Tweet (Feature):\n", X.sample(3).values)
print("\nüî∏ Sample Emotion (Target):\n", y.sample(3).values)

"""#Convert Categorical Columns to Numerical"""

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

# Step 1: Encode the 'emotion' column (target)
le = LabelEncoder()
y_encoded = le.fit_transform(df['emotion'])

# You can map back to emotion names using:
# print(dict(zip(le.classes_, le.transform(le.classes_))))

# Step 2: Convert 'tweet' text into numeric features using TF-IDF
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['tweet']).toarray()

print("TF-IDF Feature Matrix Shape:", X_tfidf.shape)
print("Encoded Labels Shape:", y_encoded.shape)

"""#One-Hot Encoding"""

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Step 1: Label Encode the target
le = LabelEncoder()
y_encoded = le.fit_transform(df['emotion'])

# Step 2: One-Hot Encode the label-encoded values
y_onehot = to_categorical(y_encoded)

# Check the result
print("Shape of One-Hot Encoded Output:", y_onehot.shape)

"""#Feature Scaling"""

from sklearn.preprocessing import StandardScaler

# Apply standard scaling to TF-IDF features
scaler = StandardScaler(with_mean=False)  # with_mean=False to avoid error with sparse matrix
X_scaled = scaler.fit_transform(X_tfidf)

"""#Train-Test Split"""

from sklearn.model_selection import train_test_split

# Use X_scaled if you've done feature scaling, otherwise use X_tfidf
X = X_scaled  # or X_tfidf if not scaled
y = y_encoded  # or y_onehot if you're using a deep learning model

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Check the shape of the result
print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)

"""#Model Building"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Initialize the model
model = LogisticRegression(max_iter=1000, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}\n")

print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""#Evaluation"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# üéØ Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"‚úÖ Accuracy: {accuracy:.4f}")

# üìä Full Classification Report
print("\nüìã Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# üßÆ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Emotion")
plt.ylabel("Actual Emotion")
plt.tight_layout()
plt.show()

"""#Make Predictions from New Input

"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Download stopwords if not already done
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)  # Remove URLs
    text = re.sub(r'\@w+|\#', '', text)  # Remove mentions/hashtags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove punctuation
    words = text.split()
    words = [stemmer.stem(word) for word in words if word not in stop_words]
    return " ".join(words)

# Sample new tweet
new_tweet = "I'm so excited and happy about my results!"

# Preprocess the tweet
processed_tweet = preprocess(new_tweet)

# Convert to TF-IDF
new_tfidf = tfidf.transform([processed_tweet])

# Predict
predicted_label = model.predict(new_tfidf)[0]
predicted_emotion = le.inverse_transform([predicted_label])[0]

print(f"üîç Predicted Emotion: {predicted_emotion}")

"""#Convert to DataFrame and Encode"""

new_tweet = "I feel terrible and sad about what happened."

import pandas as pd

# Convert new input to a DataFrame
new_df = pd.DataFrame({'tweet': [new_tweet]})

# Apply the same preprocessing function
new_df['clean_tweet'] = new_df['tweet'].apply(preprocess)

# Transform using the previously fitted TF-IDF vectorizer
new_tfidf = tfidf.transform(new_df['clean_tweet'])

# Predict using the trained model
predicted_label = model.predict(new_tfidf)[0]
predicted_emotion = le.inverse_transform([predicted_label])[0]

print(f"üîç Predicted Emotion: {predicted_emotion}")

"""#Predict the Final Grade"""

def predict_emotion(tweet):
    # Preprocess
    processed = preprocess(tweet)

    # Encode using TF-IDF
    tfidf_vector = tfidf.transform([processed])

    # Predict with trained model
    label = model.predict(tfidf_vector)[0]

    # Decode to original emotion label
    return le.inverse_transform([label])[0]

sample = "I can't stop smiling today!"
print("Predicted Emotion:", predict_emotion(sample))

"""# Deployment-Building an Interactive App

"""

!pip install gradio

import gradio as gr

# Define a function that does preprocessing + prediction
def predict_emotion(tweet):
    # Preprocess the tweet
    processed = preprocess(tweet)

    # Convert to TF-IDF
    tfidf_vector = tfidf.transform([processed])

    # Predict the emotion
    label = model.predict(tfidf_vector)[0]
    emotion = le.inverse_transform([label])[0]

    return emotion

# Define the input and output
interface = gr.Interface(
    fn=predict_emotion,
    inputs=gr.Textbox(lines=3, placeholder="Type or paste a tweet here..."),
    outputs="text",
    title="üîç Emotion Predictor",
    description="Enter a social media post to detect its underlying emotion (e.g., joy, sadness, anger, etc.)"
)

interface.launch()